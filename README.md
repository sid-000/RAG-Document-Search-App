# ðŸ§  RAG Document Search App

A full-stack **Retrieval-Augmented Generation (RAG)** pipeline that ingests documents (PDFs, TXT), indexes them into a vector store, and allows users to query those documents through a language model-powered interface.

---


## ðŸ”¹ Demo

Hereâ€™s a quick walkthrough of the app in action:

![Demo](assets/demo.gif)

---


## ðŸš€ Features

- ðŸ“¥ Upload `.pdf` and `.txt` files from your local system
- âœ‚ï¸ Automatic document chunking
- ðŸ” Embedding with `sentence-transformers` or OpenAI
- ðŸ§  Vector storage using `FAISS`
- ðŸ¤– OpenAI GPT-3.5 or GPT-4 powered Q&A
- ðŸŒ Simple UI with Streamlit

---

## ðŸ› ï¸ Tech Stack

| Component         | Tool                         |
|------------------|------------------------------|
| Chunking         | Custom, via word splitter    |
| Embeddings       | `sentence-transformers` / OpenAI |
| Vector DB        | `FAISS`                      |
| LLM Inference    | `OpenAI GPT-3.5` / `GPT-4`   |
| Frontend         | `Streamlit`                  |
| PDF Parsing      | `PyMuPDF`                    |
| API Key Handling | `python-dotenv`              |

---

## ðŸ“ Folder Structure

```bash
rag-document-search-app/
â”œâ”€â”€ data/                      # Raw documents (PDFs, TXTs)
â”œâ”€â”€ ingest/                    # Loading and chunking logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders.py
â”‚   â””â”€â”€ chunking.py
â”œâ”€â”€ embeddings/                # Embedding generation and vector store
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ embed_and_store.py
â”œâ”€â”€ retriever/                 # Query handling and retrieval
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ retrieve.py
â”œâ”€â”€ llm/                       # Prompt formatting and LLM response
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ generate.py
â”œâ”€â”€ app/                       # Streamlit frontend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env                       # Contains your OpenAI API key



---

## ðŸ”§ Setup Instructions

1. Clone the repo

```bash
git clone https://github.com/YOUR_USERNAME/Deep-Learning---Project-1.git
cd Deep-Learning---Project-1


2. Install dependencies

pip install -r requirements.txt


3. Add your OpenAI key in .env:

OPENAI_API_KEY=sk-xxxxxxxxxxxx


4. Run the app

streamlit run app/main.py




## ðŸ§ª Sample Q&A Results

**Document:** `NLP_intro.pdf`  
**Question:** What are transformers used for in NLP?  
**Retrieved Context Snippet:**  
> Transformers are used in NLP for tasks such as translation, summarization, and question answering...

**Answer:**  
Transformers are used in NLP for tasks like translation, summarization, and QA by modeling long-range dependencies using self-attention mechanisms.

---

**Document:** `transformers_overview.pdf`  
**Question:** Who introduced the transformer model?  
**Answer:**  
The Transformer model was introduced in the paper *"Attention is All You Need"* by Vaswani et al., 2017.




## ðŸ“„ Sample Documents

The RAG system was tested on real-world NLP-related PDFs:

- [Attention Is All You Need (Vaswani et al., 2017)](data/Attention_Is_All_You_Need.pdf)
- [Natural Language Processing: A Comprehensive Survey](data/NLP_Comprehensive_Survey.pdf)

These documents were embedded using `sentence-transformers`, stored using `FAISS`, and queried with natural language questions.



